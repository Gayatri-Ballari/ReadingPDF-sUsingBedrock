{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.bedrock import Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "with open(\"aws_credentials.json\", \"r\", encoding=\"utf-8-sig\") as file:\n",
    "    data = file.read()  # Read the file content\n",
    "    credentials = json.loads(data) \n",
    "\n",
    "# Extract credentials\n",
    "aws_access_key_id = credentials[\"aws_access_key_id\"]\n",
    "aws_secret_access_key = credentials[\"aws_secret_access_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_NAME = 'bedrock-runtime'\n",
    "REGION_NAME = 'ap-south-1'\n",
    "\n",
    "import boto3\n",
    "bedrock = boto3.client(\n",
    " service_name=SERVICE_NAME,\n",
    " region_name=REGION_NAME,\n",
    " aws_access_key_id=aws_access_key_id,\n",
    " aws_secret_access_key=aws_secret_access_key\n",
    " #endpoint_url=f'https://{SERVICE_NAME}.{REGION_NAME}.amazonaws.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", client=bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(llm, faiss_index, question):\n",
    "    prompt_tempalte = \"\"\"\n",
    "\n",
    "    Human: Use the following pieces of context to provide a concise answer to the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPT = PromptTemplate(template=prompt_tempalte, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=faiss_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "\n",
    "    answer =  qa({\"query\":question})\n",
    "    return answer['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    llm = Bedrock(\n",
    "        model_id=\"mistral.mistral-7b-instruct-v0:2\", \n",
    "        client=bedrock\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    faiss_index = FAISS.load_local(\n",
    "        folder_path=\"faiss_index\",\n",
    "        embeddings=bedrock_embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"what is discussed in the meeting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Deploying to production and preparing a demo\\n    2. Reviewing progress on various aspects of the project, including model fine-tuning, prompt adjustments, and data pipeline testing\\n    3. Plans for evaluating and improving model accuracy\\n    4. Setting up knowledge bases and preparing for upcoming releases and presentations\\n    5. Discussions on enabling approximately 200 Hedge employee accounts for testing\\n    6. Announcing the availability of the new system for testing during the AI First session\\n    7. Updating prompts and deploying to staging\\n    8. Setting up agents for data retrieval without embeddings\\n    9. Fine-tuning models, adjusting prompts, and ensuring the correct APIs are called to get the right data.\\n    10. Discussions on measuring and improving response accuracy.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(llm, faiss_index, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
